# Sentiment Analysis on Twitter and Reddit

### Monitoring Public Sentiment on Brands Using Social Media Data for Strategic Insights  
**Contributors:** Parnavi Sen, Navneet Parab  
**Date:** April 2025  

---

## ğŸ§  Project Overview

Public sentiment significantly impacts a brandâ€™s reputation, market value, and customer trust. Yet, many brands lack the tools to analyze real-time feedback shared by users on platforms like Twitter and Reddit. This project presents a robust NLP pipeline to **monitor, classify, and visualize sentiment trends** for brands using social media data.

We leverage both traditional models and state-of-the-art transformer-based deep learning architectures to understand nuanced, context-aware sentiment and provide actionable insights to brands for product and communication strategy.

---

## ğŸ¯ Project Goals

- Collect and preprocess large-scale datasets from Twitter and Reddit.
- Apply lexicon-based, clustering, and transformer models for sentiment classification.
- Compare model performance (accuracy, interpretability, efficiency).
- Use LLMs (BERT, Gemini) to:
  - Detect mixed or ambiguous sentiment.
  - Extract contextual sentiment cues.
  - Summarize trends and topic clusters.
- Visualize sentiment trends over time with interactive dashboards.
- Provide actionable insights to enhance brand strategy and engagement.

---

## ğŸ—ƒï¸ Dataset Details

The Reddit dataset was collected using the PRAW (Python Reddit API Wrapper) and includes:

- `Subreddit`: Community where the post originated.
- `Timestamp`: Post creation date and time.
- `Title` and `Body`: Main textual content.
- `First Comment`: Top user comment on the post.
- `Upvotes` and `Upvote Ratio`: Measures of community approval.
- `Number of Comments`: Engagement metric.

Two domains were analyzed:
- **Athletic Apparel Brands**
- **Technology Companies**

---

## ğŸ§¹ Preprocessing Pipeline

### ğŸ”¤ Text Clean-Up
- Lowercased text
- Removed punctuation, special characters, numbers
- Removed stopwords (using NLTK)

### ğŸ§  NLP Tasks
- Tokenization  
- Lemmatization  
- POS tagging  
- Emoji normalization (using `emoji` package)

### ğŸ¤– Transformer Input Processing
- BERT subword tokenization
- Attention masks and padding
- Uniform input formatting for deep models

---

## ğŸ§ª Models Used

### ğŸ”¹ Lexicon-Based
- **VADER**: Lightweight rule-based model for polarity scoring

### ğŸ”¹ Unsupervised Learning
- **K-Means**: Clustered sentiment-rich post vectors (TF-IDF) to create pseudo-labels

### ğŸ”¹ Transformer-Based Deep Learning
- **BERT (`bert-base-uncased`)**
  - Context-aware embedding
  - Fine-tuned on pseudo-labeled Reddit data
  - Achieved 85â€“90% accuracy

- **Gemini**
  - Efficient transformer architecture (used in place of LLaMA)
  - Fine-tuned with mixed precision & gradient checkpointing
  - Lower memory footprint, good for deployment

---

## âœ… Results

| Model   | Type       | Accuracy | Notes |
|---------|------------|----------|-------|
| VADER   | Rule-based | â€“        | Used for pseudo-labels |
| K-Means | Clustering | â€“        | Unsupervised label generation |
| BERT    | Transformer| 85â€“90%   | Best performance, handles context and sarcasm |
| Gemini  | Transformer| ~80â€“85%  | Lightweight alternative to BERT |

- **Visualizations**: Sentiment trends, confusion matrices, accuracy/loss curves.
- **Findings**:
  - Neutral sentiment dominated across both domains.
  - Positive sentiment reflected strong brand loyalty.
  - Sarcasm and ambiguity remained challenges.

---

## ğŸ“ˆ Tools & Technologies

### ğŸ Languages & Frameworks
- Python  
- TensorFlow, PyTorch  
- Scikit-learn, Transformers (Hugging Face)

### ğŸ§° Libraries
- Data Collection: `PRAW`, `snscrape`
- NLP: `nltk`, `spaCy`, `emoji`
- Modeling: `transformers`, `scikit-learn`, `tensorflow`
- Visualization: `matplotlib`, `seaborn`, `plotly`

### â˜ï¸ Platforms
- **Google Colab / Jupyter** â€“ Training and experimentation  
- **AWS** â€“ For scalable deployment  
- **Tableau / Power BI** â€“ Dashboard visualization  

---

## ğŸ“Š Expected Output

- Trained sentiment classification model (BERT and Gemini variants)
- Visualization dashboards for:
  - Sentiment over time
  - Top keywords per sentiment class
  - Emerging discussion themes
- Strategic insights to help brands respond to public opinion

---

## ğŸš€ Future Work

- Improve sarcasm detection using models like RoBERTa, T5
- Expand to additional platforms (Twitter, Instagram)
- Add domain-specific fine-tuning for healthcare/finance/etc.
- Use active learning or semi-supervised methods to improve label quality
- Develop lightweight APIs and deploy on edge devices

---

## ğŸ“¬ Contact

For questions, collaboration, or feedback:  
ğŸ“§ Parnavi Sen â€” [parnavi.sen.ps@gmail.com](mailto:parnavi.sen.ps@gmail.com)  
ğŸ“§ Navneet Parab â€” [navneetparabb20@gmail.com](mailto:navneetparabb20@gmail.com)

---



